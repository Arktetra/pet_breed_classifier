{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import regex as re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.OxfordIIITPet(\n",
    "    root = \"data\",\n",
    "    split = \"trainval\",\n",
    "    download = True,\n",
    "    transform = v2.Compose([\n",
    "        v2.ToImage(),\n",
    "        v2.RandomResizedCrop(size = (224, 224), antialias = True),\n",
    "        v2.RandomHorizontalFlip(p = 0.5),\n",
    "        v2.ToDtype(torch.float32, scale = True),\n",
    "        v2.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_data = datasets.OxfordIIITPet(\n",
    "    root = \"data\",\n",
    "    split = \"test\",\n",
    "    download = True,\n",
    "    transform = v2.Compose([\n",
    "        v2.ToImage(),\n",
    "        v2.Resize(256),\n",
    "        v2.CenterCrop(224),\n",
    "        v2.ToDtype(torch.float32, scale = True),\n",
    "        v2.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalize in tranform dismisses the color changes or small intensity changes of the same content in different images. This will enable the model to learn the real structures instead of dealing with the scale differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"data/oxford-iiit-pet\")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    path / \"annotations/test.txt\",\n",
    "    sep = \" \",\n",
    "    names = ['Breed', 'Class ID', 'Species', 'Breed ID']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {class_id: \"\".join(re.findall(r\"(.+)_\\d+$\", breed))\n",
    "             for breed, class_id in zip(df['Breed'], df['Class ID'] - 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train': training_data,\n",
    "    'test': test_data\n",
    "}\n",
    "\n",
    "datasets_size = {\n",
    "    'train': len(training_data),\n",
    "    'test': len(test_data)\n",
    "}\n",
    "\n",
    "dataloaders = {x: DataLoader(\n",
    "                    datasets[x],\n",
    "                    shuffle = True,\n",
    "                    batch_size = 64,\n",
    "                    num_workers = 2,\n",
    "                    persistent_workers = True,\n",
    "                    pin_memory = True\n",
    "                ) for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = Path(tempdir) / \"best_models_params.pt\"\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        history = {'train': [], 'test': []}\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'test']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / datasets_size[phase]\n",
    "                epoch_acc = running_corrects.double() / datasets_size[phase]\n",
    "\n",
    "                history[phase].append((epoch_loss, epoch_acc))\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Corrects: {running_corrects} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'test' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best test Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `resnet18` model and freeze it. Then replace the model head with a sequential layer and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights = models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "for param in model.parameters():\n",
    "  if isinstance(param, nn.Conv2d):\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features = num_features, out_features = 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features = 256, out_features = 37)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "\n",
    "model = train_model(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    exp_lr_scheduler,\n",
    "    15\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
